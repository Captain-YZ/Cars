{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52287d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca68225a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Cleaned_Comment\n",
      "0  è½¦é•¿ æ¥è¿‘ 5m ç©ºé—´ å‰æ’ ç©ºé—´ å¾ˆå¤§ åæ’ è…¿éƒ¨ ç©ºé—´ è®¾è®¡ å¤´é¡¶ ç©ºé—´ åå° 185 ...\n",
      "1  ç©ºé—´ ç®—æ˜¯ åŠ£åŠ¿ æ¯•ç«Ÿ è½¦å­ æ•´ä½“ éš¾æ ç¬¬äºŒæ’ å‚¨ç‰© ç©ºé—´ åªæœ‰ åå¤‡ç®± å‰é¢ æŒ¤å‡ºæ¥ å‰...\n",
      "2  è¿™è¾† å†…éƒ¨ç©ºé—´ å…¶å® å¤–éƒ¨ å°ºå¯¸ æ¯”ä¾‹ è¿™ä¹ˆ è¿™è¾† é•¿åº¦ è¾¾åˆ° ç±³å·¦å³ è½¦å†… è…¿éƒ¨ ç©ºé—´ æƒ³...\n",
      "3  å¾ˆå¤š åæ’ ç©ºé—´ å®é™…ä¸Š ä¸å° é™¤é ä¸€ç±³ å…«äº” èº«é«˜ è¶³å¤Ÿ èµ·æ­¥ å¾ˆå¿« æ–¹å‘ çµæ• å¥½å¼€ ...\n",
      "4  å†…éƒ¨ ç©ºé—´è®¾è®¡ å…¶å® ä¸é”™ è½¦å†… å‚¨ç‰© èƒ½åŠ› ä¸­æ§ æ‰¶æ‰‹ ä¸‹é¢ è¿˜æœ‰ ç©ºæ—· ä½ç½® å‰å¤‡ åæ’...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "\n",
    "# ğŸ”¹ 1. è¯»å–æ•°æ®\n",
    "data = pd.read_excel(r\"äºŒæ‰‹æ±½è½¦å£ç¢‘.xlsx\")\n",
    "\n",
    "# ğŸ”¹ 2. æŒ‡å®šä½ éœ€è¦å¤„ç†çš„åˆ—\n",
    "columns_to_process = ['ç©ºé—´', 'é©¾é©¶æ„Ÿå—', 'æ“æ§', 'ç»­èˆª', 'èˆ’é€‚æ€§', 'å¤–è§‚', 'å†…é¥°', 'æ€§ä»·æ¯”', 'æ™ºèƒ½åŒ–']\n",
    "\n",
    "# ğŸ”¹ 3. è¯»å–åœç”¨è¯å’Œæ±½è½¦è¯æ±‡\n",
    "with open(r\"stopped_words.txt\", 'r', encoding='utf-8') as f:\n",
    "    stopwords = set(f.read().splitlines())\n",
    "\n",
    "with open(r\"æ±½è½¦è¯æ±‡è¯åº“.txt\", 'r', encoding='utf-8') as f:\n",
    "    car_terms = set(f.read().splitlines())\n",
    "\n",
    "# ğŸ”¹ 4. æ–‡æœ¬æ¸…æ´—å‡½æ•°ï¼šæ‹¼æ¥å¤šä¸ªç»´åº¦è¯„è®º -> åˆ†è¯ -> å»åœç”¨è¯ -> ç­›é€‰æ±½è½¦è¯æ±‡/é•¿åº¦>1\n",
    "def clean_and_tokenize_row(row):\n",
    "    combined_text = ' '.join(str(row[col]) for col in columns_to_process if pd.notna(row[col]))\n",
    "    words = jieba.lcut(combined_text)\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    words = [word for word in words if word in car_terms or len(word) > 1]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# ğŸ”¹ 5. åº”ç”¨å¤„ç†å‡½æ•°ï¼Œç”Ÿæˆæ–°åˆ—\n",
    "data['Cleaned_Comment'] = data.apply(clean_and_tokenize_row, axis=1)\n",
    "\n",
    "# ğŸ”¹ 6. æŸ¥çœ‹å‰å‡ è¡Œç»“æœ\n",
    "print(data[['Cleaned_Comment']].head())\n",
    "# ğŸ”¹ 7. è¦†ç›–åŸæ–‡ä»¶\n",
    "data.to_excel(r\"äºŒæ‰‹æ±½è½¦å£ç¢‘.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c738a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”¹ 4. åˆ’åˆ†æ•°æ®é›†\n",
    "X = data['Cleaned_Comment']\n",
    "y = data['Sentiment']\n",
    "# è¿™æ˜¯å®ƒæœ‰ä¸€éƒ¨åˆ†è‡ªå¸¦çš„æ ‡ç­¾ï¼Œä½†æ˜¯å…¶ä»–çš„æ²¡æœ‰ï¼Œæ‰€ä»¥éœ€è¦å†é¢„æµ‹\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# ğŸ”¹ 5. ç‰¹å¾æå–ï¼šTF-IDF\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=10000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9582b0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å‰5æ¡é¢„æµ‹ç»“æœå¦‚ä¸‹ï¼š\n",
      "                                          clean_comment     Predicted  \\\n",
      "8188  å°è½¦ ç©ºé—´ å¾ˆå¤§ æ¯•ç«Ÿ ä¸­å‹ SUV å®½æ• è½¦å­ åŠ¨åŠ› å……è¶³ åŠ é€Ÿ å¾ˆå¿« é¿éœ‡ æ•ˆæœ éš”éŸ³ ...  non-positive   \n",
      "298   ç©ºé—´ å¾ˆå¤§ åå¤‡ç®± å¾ˆèƒ½ åæ’ åº§æ¤… ç©ºé—´è®¾è®¡ åˆ©ç”¨ç‡ è¿˜æœ‰ å‰å¤‡ ä½¿ç”¨ é¢‘ç‡ è½¦å¤´ é©¾é©¶ ...  non-positive   \n",
      "9140  ç©ºé—´ ç¬¬ä¸‰æ’ åº§æ¤… æ”¾å¹³ æ”¾å¹³ åå¤‡ç®± ç©ºé—´ æ‰©å±• èƒ½è£… ç¬¬ä¸‰æ’ ç©ºé—´ ç›¸å¯¹ ä¸¤æ’ ç©ºé—´ ä¸€...      positive   \n",
      "3199  æ¯•ç«Ÿ è½´è· è½¦èº« å°ºå¯¸ æ‘†åœ¨ é‚£é‡Œ ç©ºé—´ å……è£• ä¿è¯ æ¯ä¸ª èˆ’é€‚ ä¹˜å ç©ºé—´ å‰æ’ é©¾é©¶ ç©º...      positive   \n",
      "1572  ä¹˜å ç©ºé—´ ä¸é”™ è¿™ä¹ˆ èº«æ é©¾é©¶åº§ å®½å®½æ¾æ¾ åæ’ ä½“éªŒ èº«æ åä¸‰äºº æœ‰ç‚¹ æ‹¥æŒ¤ ä¹˜å ...      positive   \n",
      "\n",
      "      Positive_Score  Negative_Score  \n",
      "8188        0.451032        0.548968  \n",
      "298         0.449290        0.550710  \n",
      "9140        0.702258        0.297742  \n",
      "3199        0.614279        0.385721  \n",
      "1572        0.532724        0.467276  \n"
     ]
    }
   ],
   "source": [
    "# å‡è®¾ X_test æ˜¯ä¸€ä¸ªåŒ…å« clean_comment çš„ Series æˆ– DataFrame\n",
    "# å¦‚æœä½ ä¹‹å‰ä½¿ç”¨çš„æ˜¯ Seriesï¼Œå¯ä»¥è¿™æ ·è½¬æˆ DataFrameï¼Œå¹¶å‘½ååˆ—\n",
    "X_test_df = X_test.to_frame(name='clean_comment')\n",
    "\n",
    "# è®­ç»ƒæ¨¡å‹\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# é¢„æµ‹\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "y_pred_proba = model.predict_proba(X_test_tfidf)\n",
    "\n",
    "# æ„å»ºåŒ…å« clean_comment å’Œé¢„æµ‹ä¿¡æ¯çš„ DataFrame\n",
    "results = X_test_df.copy()\n",
    "results['Predicted'] = y_pred\n",
    "results['Positive_Score'] = y_pred_proba[:, 1]\n",
    "results['Negative_Score'] = y_pred_proba[:, 0]\n",
    "\n",
    "# ä¿å­˜ä¸º Excel æ–‡ä»¶\n",
    "output_path = 'ç®€åŒ–æƒ…æ„Ÿé¢„æµ‹ç»“æœ.xlsx'\n",
    "results.to_excel(output_path, index=False)\n",
    "\n",
    "# æ‰“å°å‰ 5 è¡Œ\n",
    "print(\"å‰5æ¡é¢„æµ‹ç»“æœå¦‚ä¸‹ï¼š\")\n",
    "print(results.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
